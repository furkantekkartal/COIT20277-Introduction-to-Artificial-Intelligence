# W07 - Convolutional Neural Networks

![picture](./Images/w07_L01.png)

## Lecture Example 1: Handwritten Digits Image Classifier - W07_Lecture_Page19

```
#1------------------------------------------------------------------------------
# Imports:

import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from keras.models import Sequential
from keras import optimizers
from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D

'''
• numpy: Used for numerical operations and array manipulation.
• matplotlib.pyplot: Used for data visualization.
• datasets: From scikit-learn, used to load the MNIST dataset.
• train_test_split: From scikit-learn, used to split the dataset into training and testing sets.
• to_categorical: From Keras, used to convert class vectors to binary class matrices (one-hot encoding).
• Sequential, Dense, Activation, Flatten, Conv2D, MaxPooling2D: These are various components from Keras needed to define the CNN architecture.
'''


#2------------------------------------------------------------------------------
# Load Data:
data = datasets.load_digits()
X_data = data.images
y_data = data.target

'''
• datasets.load_digits(): Loads the MNIST dataset containing images of handwritten digits and their corresponding labels.
• X_data: Contains the images.
• y_data: Contains the corresponding labels
'''


#3------------------------------------------------------------------------------
# Data Preprocessing:

# reshape X_data into 3-D format
# note that this follows image format of TensorFlow backend
X_data = X_data.reshape(X_data.shape[0], X_data.shape[1], X_data.shape[2], 1)

# one-hot encoding of y_data
y_data = to_categorical(y_data)

# partition data into train/test sets
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 777)

'''
• Reshaping: Reshapes the image data to a 4D tensor suitable for input to a convolutional layer.
  • Number of Samples: This dimension represents the number of images in your dataset.
  • Image Height: This dimension represents the height (number of rows) of each image.
  • Image Width: This dimension represents the width (number of columns) of each image.
  • Number of Channels: This dimension represents the number of channels in each image. 

• One-Hot Encoding: Converts the labels to one-hot encoded format.
  • A method used to represent categorical variables as binary vectors, where each unique category is represented by a binary value, typically 1 for the category present and 0 for all others.

• Train-Test Split: Splits the dataset into training and testing sets with a test size of 30% and a random state for reproducibility
'''


#4------------------------------------------------------------------------------
# Model Definition:

model = Sequential()
# convolution Layer 
model.add(Conv2D(input_shape=(X_data.shape[1], X_data.shape[2], X_data.shape[3]), filters = 10, kernel_size = (3,3), strides = (1,1), padding = 'valid'))
# activation layer before pooling
model.add(Activation('relu'))
# pooling layer
model.add(MaxPooling2D(pool_size = (2,2)))
# prior layer should be flattened to be connected to dense layers
model.add(Flatten())
# dense layer with 50 neurons
model.add(Dense(50, activation = 'relu'))
# final layer with 10 neurons to classify the instances
model.add(Dense(10, activation = 'softmax'))


'''
• Sequential Model: Defines a sequential model.
• Conv2D Layer: Adds a 2D convolutional layer with 10 filters, a kernel size of (3,3), and ReLU activation.
• Activation Layer: Applies ReLU activation function.
• MaxPooling2D Layer: Adds a max-pooling layer.
• Flatten Layer: Flattens the output from the previous layer.
• Dense Layers: Adds fully connected (dense) layers with ReLU activation.
• Final Dense Layer: Adds a final dense layer with softmax activation for multi-class classification.
'''


#5------------------------------------------------------------------------------
# Model Compilation:

adam = optimizers.Adam(learning_rate = 0.001)
model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])

'''
• Adam Optimizer: Uses the Adam optimizer with a learning rate of 0.001.
• Categorical Crossentropy Loss: Sets the loss function for multi-class classification.
• Metrics: Evaluates the model performance using accuracy.
'''

#6------------------------------------------------------------------------------
# Model Training:

history = model.fit(X_train, y_train, batch_size = 50, validation_split = 0.2, epochs = 100, verbose = 0)
'''
• Model.fit( ): Trains the model on the training data with a batch size of 50, validation split of 20%, for 100 epochs
'''

#7------------------------------------------------------------------------------
# Model Evaluation:

results = model.evaluate(X_test, y_test)
print("Test Loss:", results[0])
print("Test accuracy:", results[1])

'''
• Model.evaluate( ): Evaluates the trained model on the test data and prints the test loss and accuracy.
'''

'''
• The code in these 6 slides together demonstrates the complete process of 
building, training, and evaluating a CNN model for handwritten digit 
recognition/classifier using the MNIST dataset. 

• It's a fundamental example of using convolutional neural networks for image 
classification tasks.
'''
```
